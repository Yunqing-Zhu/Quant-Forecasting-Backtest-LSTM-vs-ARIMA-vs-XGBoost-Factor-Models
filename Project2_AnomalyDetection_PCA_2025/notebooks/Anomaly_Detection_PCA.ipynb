{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb1d3fd4",
   "metadata": {},
   "source": [
    "# Unsupervised Anomaly Detection + PCA\n",
    "This notebook demonstrates the pipeline: load data, standardize, apply PCA for visualization, train IsolationForest and One-Class SVM, and compare anomaly scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45179a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.svm import OneClassSVM\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6645690e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/transactions.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1100061",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['is_synthetic_anomaly']).values\n",
    "y = df['is_synthetic_anomaly'].values\n",
    "scaler = StandardScaler().fit(X)\n",
    "Xs = scaler.transform(X)\n",
    "pca = PCA(n_components=2).fit(Xs)\n",
    "X_pca = pca.transform(Xs)\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.scatter(X_pca[:,0], X_pca[:,1], s=8, alpha=0.6)\n",
    "plt.title('PCA 2D scatter - all points')\n",
    "plt.xlabel('PC1'); plt.ylabel('PC2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d2c98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "iso = IsolationForest(n_estimators=200, contamination=0.02, random_state=42).fit(Xs)\n",
    "iso_scores = -iso.score_samples(Xs)\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(iso_scores, bins=80)\n",
    "plt.title('IsolationForest anomaly score distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9013a208",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "threshold = np.percentile(iso_scores, 97.5)\n",
    "preds = (iso_scores >= threshold).astype(int)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y, preds, average='binary', zero_division=0)\n",
    "print(f'Precision: {precision:.3f}, Recall: {recall:.3f}, F1: {f1:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916422da",
   "metadata": {},
   "source": [
    "## Save models and visuals\n",
    "You can run `src/train_and_score.py` to reproduce the models and save visuals to `outputs/`."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
